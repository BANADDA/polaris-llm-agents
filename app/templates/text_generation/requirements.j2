fastapi
uvicorn
torch>=2.0.0
transformers>=4.37.0
accelerate>=0.24.0
{% if not use_llama_cpp %}
# llama-cpp-python is installed via Dockerfile when needed
{% endif %}
pydantic
PyJWT>=2.0.0
firebase-admin
huggingface_hub
sentencepiece
protobuf
aiofiles
async-timeout
asyncio